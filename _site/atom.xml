<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Duygu Serbest</title>
 <link href="http://duygu.io/atom.xml" rel="self"/>
 <link href="http://duygu.io/"/>
 <updated>2016-04-29T16:08:58+03:00</updated>
 <id>http://duygu.io</id>
 <author>
   <name>Duygu Serbest</name>
   <email></email>
 </author>

 
 <entry>
   <title>Hello World!</title>
   <link href="http://duygu.io/2016/04/25/hello-world/"/>
   <updated>2016-04-25T20:23:00+03:00</updated>
   <id>http://duygu.io/2016/04/25/hello-world</id>
   <content type="html">&lt;p&gt;Hello World!&lt;/p&gt;

&lt;p&gt;This is my first post on this site so this should be a welcoming one.&lt;/p&gt;

&lt;p&gt;I studied Computer Engineering for 4 years and have been working on a software company as a Software Engineer since 2014. In this blog I will talk about technologies, frameworks I learnt, I want to learn and how things should be.&lt;/p&gt;

&lt;p&gt;I created this blog to be able to look up the solutions I came up with to a specific problems I faced, to remember how I installed softwares I used and what tools I used to solve general problems. Basically this blog is going to consist of the documentation of things I have done.&lt;/p&gt;

&lt;p&gt;My first goal about this blog is writing posts for technologies, frameworks etc. I learnt in the past six years. This includes Java, Maven, Git, SVN, Hadoop, MongoDB, HBase, Python etc.&lt;/p&gt;

&lt;p&gt;I hope my posts helps you as much as they helped me.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Installing HBase on a Distributed Hadoop Cluster</title>
   <link href="http://duygu.io/2016/04/25/hbase-installation/"/>
   <updated>2016-04-25T19:23:00+03:00</updated>
   <id>http://duygu.io/2016/04/25/hbase-installation</id>
   <content type="html">&lt;p&gt;Installation guide for distributed HBase with Zookeeper(which is a requirement for HBase, is being managed by HBase itself.).&lt;/p&gt;

&lt;h2 id=&quot;prerequisites&quot;&gt;Prerequisites:&lt;/h2&gt;
&lt;p&gt;Hadoop must be installed successfully.&lt;/p&gt;

&lt;h2 id=&quot;installation&quot;&gt;Installation:&lt;/h2&gt;
&lt;p&gt;Do everything listed below for every instance which is a node on hdfs network, you want to run HBase on.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Create a directory and navigate to created directory.
..* mkdir hbase&lt;/li&gt;
  &lt;li&gt;Change folder’s owner if needed: 
..* sudo chown -R hadoop:hadoop hbase/
..* cd hbase&lt;/li&gt;
  &lt;li&gt;Download hbase-0.94.12 to current directory.
..* wget “https://archive.apache.org/dist/hbase/hbase-0.94.12/hbase-0.94.12.tar.gz”&lt;/li&gt;
  &lt;li&gt;Extract hbase files to current directory.
..* tar -xvzf hbase-0.94.12.tar.gz&lt;/li&gt;
  &lt;li&gt;Navigate to extracted directory.
..* cd hbase-0.94.12/conf&lt;/li&gt;
  &lt;li&gt;Edit hbase-site.xml using vim.
..* vim hbase-site.xml&lt;/li&gt;
  &lt;li&gt;Set proper values to configuration properties.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;’’’&lt;/p&gt;
&lt;configuration&gt;
...
  &lt;property&gt;
    &lt;name&gt;hbase.rootdir&lt;/name&gt;
    &lt;value&gt;hdfs://{hdfs.namenode.address}:{hdfs.port}/hbase&lt;/value&gt;
    &lt;description&gt;The directory shared by RegionServers.
    &lt;/description&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;hbase.tmp.dir&lt;/name&gt;
    &lt;value&gt;/work/hbase/tmp&lt;/value&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
    &lt;description&gt;The mode the cluster will be in. Possible values are
      false: standalone and pseudo-distributed setups with managed Zookeeper
      true: fully-distributed with unmanaged Zookeeper Quorum (see hbase-env.sh)
    &lt;/description&gt;
  &lt;/property&gt;

    &lt;property&gt;
      &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
     &lt;value&gt;{zookeeper.quorum.address}&lt;/value&gt;
      &lt;description&gt;Comma separated list of servers in the ZooKeeper Quorum.
      For example, &quot;host1.mydomain.com,host2.mydomain.com,host3.mydomain.com&quot;.
      By default this is set to localhost for local and pseudo-distributed modes
      of operation. For a fully-distributed setup, this should be set to a full
      list of ZooKeeper quorum servers. If HBASE_MANAGES_ZK is set in hbase-env.sh
      this is the list of servers which we will start/stop ZooKeeper on.
      &lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;
      &lt;value&gt;/opt/zookeeper/zk-data&lt;/value&gt;
      &lt;description&gt;Property from ZooKeeper&#39;s config zoo.cfg.
      The directory where the snapshot is stored.
      &lt;/description&gt;
    &lt;/property&gt;
...
&lt;/configuration&gt;
&lt;p&gt;’’’&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Edit regionservers file and list all hosts that you would have running Zookeeper.
..* vim regionservers
..* server30
server31
server32
server33&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Add HBASE_HOME environment variable to bashrc.
..* vim ~/.bashrc
..* export HBASE_HOME=/opt/hbase/hbase-0.94.12
..* export PATH=$PATH:$HADOOP_HOME/bin:$HBASE_HOME/bin:$JAVA_HOME/bin
..* To test if variable is added successfully
..1. Logout from user session: 
..&lt;em&gt;exit
..2. Log back in:
..&lt;/em&gt; sudo su - hadoop
..3. Echo environment variable:
..* echo $HBASE_HOME&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Edit hbase-env.sh, uncomment and set proper values to properties.
..* export JAVA_HOME=/usr/lib/jvm/java-8-oracle
..* export HBASE_HEAPSIZE=4096
..* export HBASE_MANAGES_ZK=true&lt;/li&gt;
  &lt;li&gt;Symlink hdfs-site.xml under ${HBASE_HOME}/conf.
..* ln -sv /opt/hadoop/hadoop-1.0.4/conf/hdfs-site.xml hdfs-site.xml&lt;/li&gt;
  &lt;li&gt;Create HBase temp directory and Zookeeper data directory
..* cd /work
..* mkdir hbase
..* mkdir zookeeper
..* cd hbase
..* mkdir tmp
..* cd /work/zookeeper
..* mkdir zk-data&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;starting-hbase&quot;&gt;Starting HBase:&lt;/h2&gt;

&lt;p&gt;To start HBase run “./bin/start-hbase.sh” on “/opt/hbase/hbase-0.94.12” directory. The instance you have run the starter script becomes the master of the network. You must start Hadoop’s DFS and Map-Red frameworks before running this command.&lt;/p&gt;

&lt;h2 id=&quot;testing-installation&quot;&gt;Testing Installation:&lt;/h2&gt;

&lt;h3 id=&quot;checking-if-hbase-initialised-successfully&quot;&gt;Checking if HBase initialised successfully:&lt;/h3&gt;

&lt;p&gt;Run “jps” on terminal and check if “HQuorumPeer” and “HRegionServer” processes running for every instance in your HBase network. When you run “jps” command on master you should also see the master process named “HMaster”.&lt;/p&gt;

&lt;h3 id=&quot;running-hbase-check&quot;&gt;Running hbase check:&lt;/h3&gt;

&lt;p&gt;When you run “hbase hbck”, there must be no inconsistencies detected. If an inconsistency has been detected, run “hbase hbck -repair” and/or “hbase hbck -fix” for easy fix.&lt;/p&gt;

&lt;h3 id=&quot;checking-hbase-shell&quot;&gt;Checking HBase Shell:&lt;/h3&gt;

&lt;p&gt;If HBase initialised successfully, you should be able to run “hbase shell” command to access tables. After running “hbase shell” if you come across 
java.lang.RuntimeException: java.lang.UnsatisfiedLinkError: /tmp/jffi3876542469706275102.tmp: /tmp/jffi3876542469706275102.tmp: failed to map segment from shared object: Operation not permitted&lt;/p&gt;

&lt;p&gt;this exception then this means you can “not execute” on your /tmp directory.  This can mean that your company security policy block execution on tmp directory. To solve this problem you have two options: first one is giving execution permission on tmp to users, or changing java tmp directory by setting a parameter. 
To solve the problem by changing java tmp directory:
1. Create a new directory where the user you started HBase with has execution permission.
2. Add -Djava.io.tmpdir parameter to HBASE_OPTS environment variable on hbase-env.sh.
3. export HBASE_OPTS=”-Djava.io.tmpdir=/work/hbase/hbase-java-temp -XX:+UseConcMarkSweepGC”
4. Restart HBase.&lt;/p&gt;

&lt;h3 id=&quot;stopping-hbase&quot;&gt;Stopping HBase:&lt;/h3&gt;

&lt;p&gt;Run “./bin/stop-hbase.sh” on “/opt/hbase/hbase-0.94.12” directory.&lt;/p&gt;

</content>
 </entry>
 

</feed>
